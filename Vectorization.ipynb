{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Vectorization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laxman-Kumar/IST736-TextMiningAssignments/blob/master/Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6GebmMK9ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text \n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S_uFkNyK9lw",
        "colab_type": "text"
      },
      "source": [
        "<h3>Tokenization - TweetTokenizer </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMDOf1hK9l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tknzr = TweetTokenizer(reduce_len=True,strip_handles=True)\n",
        "\n",
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    return tknzr.tokenize(text)\n",
        "\n",
        "#for x in corpus:print(list(tokenize(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmt2QZLK9l5",
        "colab_type": "text"
      },
      "source": [
        "<h4>Making a dataframe of the csv file</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEpllyAaK9l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "corpus = list(df[\"TEXT\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6reUJecqK9mC",
        "colab_type": "code",
        "colab": {},
        "outputId": "95c6b631-7cce-4e43-8c46-339a6653a124"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc1Xi6MQK9mM",
        "colab_type": "text"
      },
      "source": [
        "<h4>Making list of stopwords</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm66IosaK9mO",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b8f9a48-d38e-4ced-e854-5c29226e19c7"
      },
      "source": [
        "stopwords = pd.read_csv(\"stopwords.csv\")\n",
        "stopwords = list(stopwords[\"text\"])\n",
        "print(len(stopwords))\n",
        "stopwords = text.ENGLISH_STOP_WORDS.union(stopwords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMoL2BDZK9mX",
        "colab_type": "text"
      },
      "source": [
        "<h4>Frequency Vector</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diCJsPz9K9mZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "0ac953e4-58a5-4c72-84ef-179aef63d0fc"
      },
      "source": [
        "vectorizer = CountVectorizer(binary=False, min_df = 1, analyzer = 'word',ngram_range=(1,1))\n",
        "temp = vectorizer.fit_transform([\"Hello world\",\"hello there  hello\",\"World hiii\"])\n",
        "print(list(vectorizer.vocabulary_.items()))\n",
        "temp[1].toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('hello', 0), ('world', 3), ('there', 2), ('hiii', 1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 1, 0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc10sD5_K9me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(binary=False, \n",
        "                              min_df = 5, \n",
        "                              stop_words = stopwords, \n",
        "                               analyzer = 'word',\n",
        "                                ngram_range=(1,2))\n",
        "frequencyVectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "vocabularyDict = dict(vectorizer.vocabulary_.items())\n",
        "#vocabularyDict\n",
        "vocabularyDict = sorted(vocabularyDict.items(), key = lambda kv:(kv[1], kv[0]))\n",
        "pd.DataFrame(vocabularyDict).to_csv(\"Vocabulary.csv\")\n",
        "#print(\"Length of vocab \", len(list(vectorizer.vocabulary_.items())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZRn5E3UK9ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Coded by Laxman Kumar\n",
        "def convertToCompressedRepresentaion(frequencyVectors):\n",
        "    sparseMatrix =frequencyVectors.toarray()\n",
        "    vocabDict = dict(vectorizer.vocabulary_.items())\n",
        "    vocabDict = dict(zip(vocabDict.values(),vocabDict.keys()))\n",
        "\n",
        "    compressedRepresentation = []\n",
        "    for i in range(0,len(sparseMatrix)):\n",
        "        indices = [i for i, x in enumerate(sparseMatrix[i]) if x !=0]\n",
        "        temp = {}\n",
        "        for x in indices:\n",
        "            temp[x] = sparseMatrix[i][x]\n",
        "        compressedRepresentation.append(temp)\n",
        "    return compressedRepresentation\n",
        "resultset = convertToCompressedRepresentaion(frequencyVectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCiNSDlaK9mr",
        "colab_type": "code",
        "colab": {},
        "outputId": "37be058e-ffb3-40b3-8bb1-fb1b782a41b1"
      },
      "source": [
        "type(resultset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GidFc-N4K9m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('CompressedRepresentaionFrequencyVector.txt', 'w') as file:\n",
        "     file.write(str(resultset))\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcTgblkTK9m5",
        "colab_type": "text"
      },
      "source": [
        "<h4>TFIDF Vectorization</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCzRsrd1K9m6",
        "colab_type": "code",
        "colab": {},
        "outputId": "246a35dc-e3e2-48d1-ee19-f52d040c2dfe"
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df = 5, stop_words = stop_words, analyzer = 'word',ngram_range=(1,2))\n",
        "temp =  tfidf.fit_transform(corpus)\n",
        "words = tfidf.get_feature_names()\n",
        "print(\"Length of vocab \", len(words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocab  778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__-n4mrkK9m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}